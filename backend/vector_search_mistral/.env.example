# PDF Vector Search Engine - Environment Variables
# -------------------------------------------------------------------------------
# Copy this file to .env and fill in the values for your environment.
# All API keys should be kept secure and never committed to version control.

# Mistral AI API Credentials (Required)
# Register for an API key at: https://console.mistral.ai/
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_EMBEDDING_MODEL=mistral-embed

# OpenAI API Credentials (Required for RAG enhancement features)
# Register for an API key at: https://platform.openai.com/
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Supabase Configuration (required for vector storage)
SUPABASE_PROJECT_URL=your_supabase_project_url
SUPABASE_PRIVATE_API_KEY=your_supabase_private_api_key
SUPABASE_PUBLIC_API_KEY=your_supabase_public_api_key  # Optional, only if using public API
SUPABASE_TABLE_NAME=pdf_documents  # Optional, defaults to "pdf_documents"

# Optional embedding model configurations
MISTRAL_EMBEDDING_MODEL=mistral-embed  # Default embedding model
OPENAI_EMBEDDING_MODEL=text-embedding-3-small  # Default OpenAI embedding model if using OpenAI

# Optional RAG configurations
OPENAI_MODEL=gpt-3.5-turbo  # Model for RAG features
RAG_DEFAULT_MODE=general  # Default RAG mode (general, person)
MAX_RAG_TOKENS=4096  # Maximum tokens for RAG

# Environment configuration
ENABLE_DEBUG_LOGGING=false  # Set to "true" to enable debug logs
SAVE_INTERMEDIATE_FILES=false  # Set to "true" to save intermediate processing files

# Processing Configuration
CHUNK_SIZE=500         # Default maximum chunk size in characters
CHUNK_OVERLAP=50       # Default overlap between chunks in characters
USE_RAG=false          # Whether to use RAG by default (true/false)
RAG_MODE=summarize     # Default RAG mode (summarize, analyze, explain, detail, person)

# Logging Configuration (Optional)
LOG_LEVEL=INFO         # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_FILE=              # Path to log file (leave empty for console only)

# Performance Configuration (Optional)
BATCH_SIZE=10          # Default batch size for embedding generation
MAX_RETRIES=3          # Default number of retries for API calls

# Optional: Pinecone index name (defaults to "pdf-search" if not specified)
# PINECONE_INDEX_NAME=your_custom_index_name

# Optional: Pinecone namespace (defaults to "pdf-documents" if not specified)
# PINECONE_NAMESPACE=your_custom_namespace

# Optional: Mistral model (defaults to "mistral-large-latest" if not specified)
# MISTRAL_MODEL=mistral-large-latest

# Optional: OpenAI model (defaults to "gpt-3.5-turbo" if not specified)
# OPENAI_MODEL=gpt-3.5-turbo 