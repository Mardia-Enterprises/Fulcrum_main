# PDF Vector Search Engine - Environment Variables
# -------------------------------------------------------------------------------
# Copy this file to .env and fill in the values for your environment.
# All API keys should be kept secure and never committed to version control.

# Mistral AI API Credentials (Required)
# Register for an API key at: https://console.mistral.ai/
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_EMBEDDING_MODEL=mistral-embed

# Pinecone Vector Database Credentials (Required)
# Register for an API key at: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
PINECONE_INDEX=pdf-search

# OpenAI API Credentials (Required for RAG enhancement features)
# Register for an API key at: https://platform.openai.com/
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Processing Configuration
CHUNK_SIZE=500         # Default maximum chunk size in characters
CHUNK_OVERLAP=50       # Default overlap between chunks in characters
USE_RAG=false          # Whether to use RAG by default (true/false)
RAG_MODE=summarize     # Default RAG mode (summarize, analyze, explain, detail, person)

# Logging Configuration (Optional)
LOG_LEVEL=INFO         # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_FILE=              # Path to log file (leave empty for console only)

# Performance Configuration (Optional)
BATCH_SIZE=10          # Default batch size for embedding generation
MAX_RETRIES=3          # Default number of retries for API calls

# Optional: Pinecone index name (defaults to "pdf-search" if not specified)
# PINECONE_INDEX_NAME=your_custom_index_name

# Optional: Pinecone namespace (defaults to "pdf-documents" if not specified)
# PINECONE_NAMESPACE=your_custom_namespace

# Optional: Mistral model (defaults to "mistral-large-latest" if not specified)
# MISTRAL_MODEL=mistral-large-latest

# Optional: OpenAI model (defaults to "gpt-3.5-turbo" if not specified)
# OPENAI_MODEL=gpt-3.5-turbo 